FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /root
COPY torchserve/install-torchserve.sh /torchserve/install-torchserve.sh
RUN /torchserve/install-torchserve.sh --cuda cu118
RUN /usr/local/bin/torchserve --help
COPY torchserve/config.properties /torchserve/config.properties
COPY torchserve/torchserve-entrypoint.sh /torchserve/torchserve-entrypoint.sh
ENTRYPOINT ["/torchserve/torchserve-entrypoint.sh"]

# see Dockerfile.torchserve for example, but use
# docker run --gpus all -ti iqtlabs/gamutrf-cuda-torchserve:latest bash
# ensure nvidia-container-toolkit is installed (https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
# CUDA version on the host must be same or later, than that in this container.
