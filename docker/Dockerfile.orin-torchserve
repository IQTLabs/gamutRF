FROM nvcr.io/nvidia/l4t-pytorch:r35.2.1-pth2.0-py3
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /root
COPY torchserve/install-orin-torchserve.sh /torchserve/install-orin-torchserve.sh
RUN /torchserve/install-orin-torchserve.sh
RUN /usr/local/bin/torchserve --help
COPY torchserve/config.properties /torchserve/config.properties
COPY torchserve/torchserve-entrypoint.sh /torchserve/torchserve-entrypoint.sh
CMD ["/torchserve/torchserve-entrypoint.sh"]

# 0. Always start from a clean sdkmanager, installation of Ubuntu 20.04. DO NOT attempt an in-place JetPack upgrade, DO NOT try to install docker-ce, and DO NOT try to re-install/replace CUDA without re-imaging the entire system.
# 1. Install JetPack via apt: https://docs.nvidia.com/jetson/jetpack/install-jetpack/index.html#install-jetpack. apt show nvidia-jetpack should show 5.1.2.
# 2. sudo apt-get disc-upgrade, reboot
# 3. git clone https://github.com/iqtlabs/gamutrf
# 4. cd gamutrf ; vi tests/test_torchserve.sh
# Change the docker run command line as follows:
# a) Change gamutrf-torchserve to gamutrf-orin-torchserve
# b) Insert â€”-runtime nvidia as first args, after docker run
# 5. sudo apt-get install python3-pip
# 6. Run tests/test_torchserve.sh. A successful test will print JSON prediction results. It may take 60s after the container starts, for it to return inference results as the model server installs ultralytics
